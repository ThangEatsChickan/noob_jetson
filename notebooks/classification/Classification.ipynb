{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0a770-55b9-4e8f-8ba2-5adbd211059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera stuff\n",
    "# https://github.com/NVIDIA-AI-IOT/jetcam\n",
    "from jetcam.usb_camera import USBCamera\n",
    "\n",
    "IMG_W = 224\n",
    "IMG_H = 224\n",
    "CAPTURE_W = 640\n",
    "CAPTURE_H = 480\n",
    "CAPTURE_DEVICE = 0\n",
    "camera = USBCamera(width = IMG_W, \n",
    "                   height = IMG_H, \n",
    "                   capture_width = CAPTURE_W, \n",
    "                   capture_height = CAPTURE_H, \n",
    "                   capture_device = CAPTURE_DEVICE)\n",
    "camera.running = True       # Enables callback mode\n",
    "print(\"Camera working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfac358-208f-43ba-b690-b05b7acf7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping some variables for training\n",
    "# Need dataset.py\n",
    "import torchvision.transforms as transforms\n",
    "from dataset import ImageClassificationDataset\n",
    "\n",
    "TASK = \"dog_breed\"\n",
    "CATEGORIES = [\"golden retreiver\", \"chow chow\", \"sheepdoggo\"]\n",
    "DATASETS = [\"A\", \"B\", \"C\"]\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset_dict = {}\n",
    "for name in DATASETS:\n",
    "    dataset_folder_name = \"../data/classification/\" + TASK + \"_\" + name\n",
    "    dataset_dict[name] = ImageClassificationDataset(dataset_folder_name, CATEGORIES, TRANSFORMS)\n",
    "\n",
    "print(\"{} task with {} categories defined.\".format(TASK, CATEGORIES))\n",
    "\n",
    "# Setup data directory if needed\n",
    "DATA_DIR = \"/nvdli-nano/data/classification/\"\n",
    "!mkdir -p {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8078a4b-c8b9-437d-a952-21d488e013ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection widget\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "working_dataset = dataset_dict[DATASETS[0]]\n",
    "camera.unobserve_all()\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, \"value\"), (camera_widget, \"value\"), transform=bgr8_to_jpeg)\n",
    "\n",
    "dataset_widget = ipywidgets.Dropdown(options = DATASETS, descriptions = \"dataset\")\n",
    "category_widget = ipywidgets.Dropdown(options = working_dataset.categories, description = \"category\")\n",
    "count_widget = ipywidgets.IntText(description = \"count\")\n",
    "save_widget = ipywidgets.Button(description = \"add\")\n",
    "\n",
    "count_widget.value  = working_dataset.get_count(category_widget.value) # update count\n",
    "\n",
    "def set_dataset(p_dataset):\n",
    "    global working_dataset\n",
    "    working_dataset = dataset_dict[p_dataset[\"new\"]]\n",
    "    count_widget.value = working_dataset.get_count(category_widget.value)\n",
    "\n",
    "def update_count(p_count):\n",
    "    count_widget.value = working_dataset.get_count(p_count[\"new\"])\n",
    "\n",
    "def save(img):\n",
    "    working_dataset.save_entry(camera.value, categroy_widget.value)\n",
    "    count_widget.value = working_dataset.get_count(cateory_widget.value)\n",
    "\n",
    "dataset_widget.observe(set_dataset, names = \"value\")\n",
    "count_widget.observe(update_count, names = \"value\")\n",
    "save_widget.on_click(save)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget]), dataset_widget, category_widget, count_widget, save_widget\n",
    "])\n",
    "\n",
    "print(\"data collection widget created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354be8c-27c0-4065-8744-d5087dc65db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection stuff\n",
    "import torch\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# RESNET 18\n",
    "model = torchvision.models.resnet18(pretrained = True)\n",
    "# model = torchvision.models.resnet34(pretrained = True) for RESNET 34\n",
    "model.fc = torch.nn.Linear(512, len(working_dataset.categories))\n",
    "\n",
    "# ALEXNET\n",
    "# model = torchvision.models.alexnet(pretrained = True)\n",
    "# model.classifier[-1] = torch.nn.Linear(4096, len(working_dataset.categories))\n",
    "\n",
    "# SQUEEZENET\n",
    "# model = torchvision.models.squeezenet1_1(pretrained = True)\n",
    "# model.classifier[1] = torch.nn.Conv2d(512, len(working_dataset.categories), kernel_size = 1)\n",
    "# model.num_classes = len(working_dataset.categories)\n",
    "\n",
    "model = model.to(device)\n",
    "model_save_button = ipywidgets.Button(description = \"save model\")\n",
    "model_load_button = ipywidgets.Button(description = \"load model\")\n",
    "model_path = \"/nvdli-nano/data/classification/model-\" + datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\") + \".pth\"\n",
    "model_path_widget = ipywidgets.Text(description = \"model path\", value = model_path)\n",
    "\n",
    "def load_model_cb(param):\n",
    "    model.load_state_dict(torch.load(model_path_widget.value))\n",
    "\n",
    "def save_model_cb(param):\n",
    "    torch.save(model.state_dict(), model_path_widget.value)\n",
    "\n",
    "model_load_button.on_click(load_model_cb)\n",
    "model_save_button.on_click(save_model_cb)\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button])\n",
    "])\n",
    "print(\"Model configured and model widget created.\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1d01a-9772-40f5-a272-f159e04205dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live demo widget setup\n",
    "import threading\n",
    "import time\n",
    "from utils import preprocess \n",
    "import torch.nn.functional as F\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options = [\"stop\", \"live\"], description = \"state\", value = \"stop\")\n",
    "prediction_widget = ipywidgets.Text(description = \"prediction\")\n",
    "score_widget_list = []\n",
    "\n",
    "for category in working_dataset.categories:\n",
    "    score_widget = ipywidgets.FloatSlider(min = 0.0, max = 1.0, description = category, orientation = \"vertical\")\n",
    "    score_widget_list.append(score_widget)\n",
    "\n",
    "def live_cb(p_state_widget, p_model, p_camera, p_prediction_widget, p_score_widget):\n",
    "    global working_dataset\n",
    "    while p_state_widget.value == \"live\":\n",
    "        image = p_camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = p_model(preprocessed)\n",
    "        output = F.softmax(output, dim = 1).detach().cpu().numpy().flatten() # Converting eval result into probabilty\n",
    "        category_index = output.argmax()\n",
    "        p_prediction_widget.value = working_dataset.categories[category_index]\n",
    "        for i, score in enumerate(list(output)):\n",
    "            score_widget_list[i].value = score\n",
    "            \n",
    "def start_live_cb(state):\n",
    "    if state[\"new\"] == \"live\":\n",
    "        execute_thread = threading.Thread(target = live, \n",
    "                                          args=(state_widget, model, camera, prediction_widget, score_widget))\n",
    "        execute_thread.start()\n",
    "    \n",
    "state_widget.observe(start_live_cb , names = \"value\")\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox(score_widget_list),\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "print(\"live_execution_widget created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811623-9c23-47a3-8a00-c8c29c505b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation\n",
    "BATCH_SIZE = 0\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "\n",
    "epochs_widget = ipywidgets.IntText(description = \"epochs\", value = 1)\n",
    "eval_button = ipywidgets.Button(description = \"evaluate\")\n",
    "train_button = ipywidgets.Button(description = \"train\")\n",
    "loss_widget = ipywidgets.FloatText(description = \"loss\")\n",
    "accuracy_widget = ipywidgets.FloatText(description = \"accuracy\")\n",
    "progress_widget = ipywidgets.FloatProgress(min = 0.0, max = 1.0, description = \"progress\")\n",
    "\n",
    "def train_eval_button_cb(is_training):\n",
    "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, working_dataset, optimizer\n",
    "    global eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "    \n",
    "    try:\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            working_dataset,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            shuffle = True\n",
    "        )\n",
    "        \n",
    "        state_widget.value = \"stop\"\n",
    "        train_button.disabled, eval_button.disabled = True\n",
    "        time.sleep(1)\n",
    "        \n",
    "        if is_training:\n",
    "            model = model.train()\n",
    "        else:\n",
    "            model = model.eval()\n",
    "        while epochs_widget.value > 0:\n",
    "                i = 0\n",
    "                loss_sum, error_count = 0.0\n",
    "                for images, labels in iter(train_loader):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    if is_training:\n",
    "                        optimizer.zero_grad() # zero gradients of parameters\n",
    "                \n",
    "                    output_list = model(images)\n",
    "                    loss = F.cross_entropy(output_list, labels) \n",
    "                \n",
    "                    if is_training:\n",
    "                        loss.backward() # backpropogation\n",
    "                        optimizer.step() # adjust parameters with optimizer\n",
    "                \n",
    "                    error_count += len(torch.nonzero(outputs.argmax(1) - labels).flatten()) # update progress\n",
    "                    count = len(labels.flatten())\n",
    "                    i += count\n",
    "                    loss_sum += float(loss)\n",
    "                    progress_widget.value = i / len(dataset)\n",
    "                    loss_widget.value = sum_loss / i\n",
    "                    accuracy_widget.value = 1.0 - error_count / i\n",
    "            \n",
    "                if is_training:\n",
    "                    epochs_widget.value = epochs_widget.value - 1\n",
    "                else:\n",
    "                    break\n",
    "    except e:\n",
    "        pass\n",
    "    model = model.eval()\n",
    "    train_button.disabled, eval_button.disabled = False\n",
    "    state_widget.value = \"live\"\n",
    "\n",
    "train_button.on_click(lambda cb: train_eval_button_cb(is_training = True))\n",
    "eval_button.on_click(lambda cb: train_eval_button_cb(is_training = False))\n",
    "\n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    progress_widget,\n",
    "    loss_widget,\n",
    "    accuracy_widget,\n",
    "    ipywidgets.HBox([train_button, eval_button])\n",
    "])\n",
    "\n",
    "print(\"Trainer configured and training widget created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39816142-160e-4e5c-b5a5-9122f847d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([data_collection_widget, live_execution_widget]),\n",
    "    train_eval_widget,\n",
    "    model_widget\n",
    "])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f94227-f752-4f98-b1c8-49ae25869885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect kernel and camera (the usb camera simply disconnects WITH the kernel, not much else to do)\n",
    "import os\n",
    "import IPython\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
